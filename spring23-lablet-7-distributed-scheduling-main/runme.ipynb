{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb238c27",
   "metadata": {},
   "source": [
    "# Distributed Scheduling\n",
    "The lablet aims to introduce performance gains and overheads of distributed scheduling policies in various scenarios. Distributed scheduling can be implemented with many goals in mind such as load balancing, efficient job placement, etc. In this lablet we focus on the load balancing and evaluate the performance of the receiver-initiated and server-initiated policies described here. A distributed scheduling policy has the following components:\n",
    "* **Transfer policy:** when to transfer a process?\n",
    "* **Selection policy:** which process to transfer?\n",
    "* **Location policy:** where to transfer the process?\n",
    "\n",
    "We explore two policies on a set of servers, each with a task queue where the jobs wait until they can run:\n",
    "### Sender-Initiated\n",
    "In this policy, the overloaded servers (servers with a task length size above a specified threshold), try to decrease the job waiting time by transfering jobs to other servers. In this case, we select a job from the end of the queue and select a server at random to poll. The polled server accepts the new load (job) if its queue length is lower than the threshold. Otherwise we poll another server.\n",
    "\n",
    "### Receiver-Iniated\n",
    "In this policy, the underloaded servers (servers with a task queue length above a specified threshold), try to increase their own load by borrowing jobs from other servers. In this case, we select a server at random to poll and ask if it has a job to send. The polled server sends the load (job) if its queue length is higher than the threshold.\n",
    "\n",
    "\n",
    "\n",
    "## Scenario\n",
    "Consider a cluster of $N$ servers connected through a network. We explore the effect of different policies on  total messages sent between servers and total job migrations.\n",
    "- **Part 0**: Describe the Cluster Simulation Input and Output\n",
    "- **Part 1**: Evaluate the effect of policy under different utilizations\n",
    "- **Part 2**: Evaluate the effect of Queue length\n",
    "- **Part 3**: Evaluate the effect of Search length\n",
    "- **Part 4**: Feedback forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6c9dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from src.simulate import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92313cf9",
   "metadata": {},
   "source": [
    "## Part 0: Cluster Simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a4fb65",
   "metadata": {},
   "source": [
    "### Simulator Components:\n",
    "- **Cluster**: A cluster is a collector of servers. In this setting we assume that cluster servers are homogenous and all servers are connected.\n",
    "\n",
    "- **Server**: A server presents a processing entity. The server follows a policy and has a queue threshold. The server holds a queue where tasks are submitted to simulate an expected utilization. \n",
    "- **Task**: A task is schedulable entity. A task can be in one of three states (QUEUED, RUN, and DONE). Tasks are movable between servers.\n",
    "\n",
    "### Starting a simulation instance\n",
    "> run_simulation(servers_number, simulation_time, utilization, policy, search_limit, queue_threshold)\n",
    "- **servers_number (+ve int):** The cluster Size\n",
    "- **simultion_time (+ve int, > 300):** The experiment length in seconds (We note that experiment time should be large enough to reach steady-state). \n",
    "- **utilization (float (0, 1)):** Expected  utilization value. This denotes the average utilization of the nodes in the cluster.\n",
    "- **policy (str (sender|receiver)):** applied policy.\n",
    "- **search_limit (int):** Number of proped servers\n",
    "- **queue_threshold (int):** Queue length that triggers the policy (Try values no larger than 6).\n",
    "\n",
    "### Output\n",
    "The simulation returns a Pandas Dataframe with the following columns:\n",
    "* **server**: Server ID\t\n",
    "* **total_tasks**: Total Processed Tasks by the server\n",
    "* **total_time**: Total processing time by the server\n",
    "* **messages**: Total sent messages by the server\n",
    "* **migrations**: Total migrations initated by the server\t\n",
    "* **queue_length**: Average Queue length\n",
    "* **utilization**: Experiment Utilization \n",
    "* **policy**: Experiment Policy\n",
    "* **effective_utlization**: Actual utilization (total_time/simultion_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaca40a",
   "metadata": {},
   "source": [
    "### Ex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2a255a",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_simulation(5, 1000, 0.8, \"sender\", 3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1eb7a2",
   "metadata": {},
   "source": [
    "__NOTE: Once you run a simulation or set of simulations, please don't stop the kernel/notebook, as it will crash and you will need to re-run everything from the beginning.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccdb5a8",
   "metadata": {},
   "source": [
    "## Running Experiements\n",
    "We provide a function called `run_experiments()`, which is a wrapper for the `run_simulations()` function to include caching in case the same experiment is repeated. You are going to be using this function for the rest of the lablet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c709a7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# common configurations. Please don't change.\n",
    "servers_number = 5\n",
    "simulation_time = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91dad0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of colors used for plotting. Please don't change.\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eacc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8199331d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(servers_number, simulation_time, utilization, policy, search_limit, queue_threshold):\n",
    "    if (servers_number, simulation_time, utilization, policy, search_limit, queue_threshold) in cache:\n",
    "        return cache[(servers_number, simulation_time, utilization, policy, search_limit, queue_threshold)]\n",
    "    else:\n",
    "        df = run_simulation(servers_number, simulation_time, utilization, policy, search_limit, queue_threshold)\n",
    "        cache[(servers_number, simulation_time, utilization, policy, search_limit, queue_threshold)] = df\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b408fe21",
   "metadata": {},
   "source": [
    "### Plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf10f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(x, sender_results, receiver_results, utilization, ax0, ax1, color):\n",
    "    sender_total_messages = []\n",
    "    receiver_total_messages = []\n",
    "    sender_cvs = []\n",
    "    receiver_cvs = []\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        df = sender_results[i]\n",
    "        messages = sum(df['messages'])\n",
    "\n",
    "        sender_total_messages.append(messages)\n",
    "        #cv = cv_func(df['queue_length'])\n",
    "        sender_cvs.append(df['migrations'].sum())\n",
    "\n",
    "        df = receiver_results[i]\n",
    "        messages = sum(df['messages'])\n",
    "\n",
    "        receiver_total_messages.append(messages)\n",
    "        #cv = cv_func(df['queue_length'].sum())\n",
    "        receiver_cvs.append(df['migrations'].sum())\n",
    "    \n",
    "    if utilization is None:\n",
    "        sender_label = 'Sender-initiated'\n",
    "        receiver_label = 'Receiver-initiated'\n",
    "    else:\n",
    "        sender_label = f'Sender-initiated, u = {utilization}'\n",
    "        receiver_label = f'Receiver-initiated, u = {utilization}'\n",
    "    \n",
    "    ax0.plot(x, sender_total_messages, label=sender_label, color=color, linestyle='solid')\n",
    "    ax0.plot(x, receiver_total_messages, label=receiver_label, color=color, linestyle='dashed')\n",
    "\n",
    "    ax1.plot(x, sender_cvs, label=sender_label, color=color, linestyle='solid')\n",
    "    ax1.plot(x, receiver_cvs, label=receiver_label, color=color, linestyle='dashed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad934eba",
   "metadata": {},
   "source": [
    "## Part 1: Effect of utilization ratio\n",
    "This scenario evaluates the effect of utilization under sender and receiver initated policy. This part introduces the tradeoffs and shows the system behavior.\n",
    "\n",
    "> For this part you will be given some tested configurations. Just run the code cell.\n",
    "\n",
    "The __utilization ratio__ denotes the expected average utilization of the nodes in the cluster. For instance, an utilization value of 0.5 means that 50% of the time the cpu is idle.\n",
    "\n",
    "The __search limit__ denotes the maximum number of servers that a node can contact other nodes to send/receive jobs in the sender-initiated and receiver-initiated policies.\n",
    "\n",
    "The __queue threshold__ denotes the amount of jobs in the queue above/below which the policies are triggered (see the explanation of these policies at the beginning of the Notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade3238c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sender_utilization_results = []\n",
    "receiver_utilization_results = []\n",
    "\n",
    "#################################\n",
    "# Configurations\n",
    "utilizations = [0.1, 0.2,0.3,0.4,0.5,0.6, 0.7, 0.8, 0.9,  0.99]\n",
    "search_limit = 5\n",
    "queue_threshold = 1\n",
    "#################################\n",
    "\n",
    "total_experiments = len(utilizations)\n",
    "exp = 1\n",
    "for utilization in utilizations:\n",
    "    print(f'Experiment {exp} of {total_experiments}, utilization ratio: {utilization:.1f}')\n",
    "    df = run_experiment(servers_number=servers_number, simulation_time=simulation_time, utilization=utilization,\n",
    "                             policy=\"sender\", search_limit=search_limit, queue_threshold=queue_threshold)\n",
    "    sender_utilization_results.append(df)\n",
    "    \n",
    "    df = run_experiment(servers_number=servers_number, simulation_time=simulation_time, utilization=utilization,\n",
    "                             policy=\"receiver\", search_limit=search_limit, queue_threshold=queue_threshold)\n",
    "    receiver_utilization_results.append(df)\n",
    "    \n",
    "    exp += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae96d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "plot(utilizations, sender_utilization_results, receiver_utilization_results,\n",
    "     None, ax0, ax1, 'tab:blue')\n",
    "ax0.set_xlabel('Utilization Ratio')\n",
    "ax0.set_ylabel('Total Messages')\n",
    "ax0.legend()\n",
    "\n",
    "ax1.set_xlabel('Utilization Ratio')\n",
    "ax1.set_ylabel('Total Migrations')\n",
    "ax1.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802b3216",
   "metadata": {},
   "source": [
    "## Part 1 Questions (25 Points):\n",
    "\n",
    "#### Answer for both sender-initiated and receiver-initiated policies.\n",
    "\n",
    "#### What is the effect of increasing the utilization ratio from 0 to 1 on the total number of messages across the cluster? Why?\n",
    "*Your answer here.*\n",
    "\n",
    "#### What is the effect of increasing the utilization ratio from 0 to 1 on the total migrations across the cluster?  Why?\n",
    "*Your answer here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45222022",
   "metadata": {},
   "source": [
    "## Part 2: Effect of queue threshold\n",
    "\n",
    "This scenario evaluates the effect of queue threshold under sender and receiver initated policy across utilizations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae63cfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sender_qt_results = {}\n",
    "receiver_qt_results = {}\n",
    "#################################\n",
    "# Test with different values and see the effect in behavior\n",
    "utilizations = []    #  <- fill in with utilization values (try not giving more than 10 values)\n",
    "thresholds = []      #  <- fill in with queue threshold values\n",
    "search_limit =       #  <- fill in with an integer value for search limit\n",
    "#################################\n",
    "\n",
    "total_experiments = len(utilizations) * len(thresholds)\n",
    "exp = 1\n",
    "for utilization in utilizations:\n",
    "    sender_qt_results[utilization] = []\n",
    "    receiver_qt_results[utilization] = []\n",
    "    for threshold in thresholds:\n",
    "        print(f'Experiment {exp} of {total_experiments}, queue threshold: {threshold}, '\n",
    "              f'utilization ratio: {utilization}')\n",
    "        df = run_experiment(servers_number=servers_number, simulation_time=simulation_time, utilization=utilization,\n",
    "                                 policy=\"sender\", search_limit=search_limit, queue_threshold=threshold)\n",
    "        sender_qt_results[utilization].append(df)\n",
    "\n",
    "        df = run_experiment(servers_number=servers_number, simulation_time=simulation_time, utilization=utilization,\n",
    "                                 policy=\"receiver\", search_limit=search_limit, queue_threshold=threshold)\n",
    "        receiver_qt_results[utilization].append(df)\n",
    "        \n",
    "        exp += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80139af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You don't need to change this part\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "colors_slice = colors[0:len(utilizations)]#['tab:blue', 'tab:orange', 'tab:green']\n",
    "for i in range(len(utilizations)):\n",
    "    plot(thresholds, sender_qt_results[utilizations[i]], receiver_qt_results[utilizations[i]],\n",
    "         utilizations[i], ax0, ax1, colors_slice[i])\n",
    "    \n",
    "ax0.set_xlabel('Queue Threshold')\n",
    "ax0.set_ylabel('Total Messages')\n",
    "ax0.legend()\n",
    "\n",
    "ax1.set_xlabel('Queue Threshold')\n",
    "ax1.set_ylabel('Total Migrations')\n",
    "ax1.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30356563",
   "metadata": {},
   "source": [
    "## Part 2 Questions (25 Points):\n",
    "\n",
    "#### Answer for both sender-initiated and receiver-initiated policies.\n",
    "\n",
    "#### What is the effect of increasing the queue threshold from 0 upwards on the total number of messages across the cluster? Why?\n",
    "*Your answer here.*\n",
    "\n",
    "#### What is the effect of increasing the queue threshold from 0 upwards on the total migrations across the cluster?  Why?\n",
    "*Your answer here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f1cb4e",
   "metadata": {},
   "source": [
    "## Part 3: Effect of search limit\n",
    "\n",
    "This scenario evaluates the effect of search limit under sender and reciever initated policy across utilizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ccac0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sender_sl_results = {}\n",
    "receiver_sl_results = {}\n",
    "#################################\n",
    "# Test with different values and see the effect in behavior\n",
    "utilizations = []    #  <- fill in with utilization values (try not giving more than 10 values)\n",
    "search_limits = []   #  <- fill in with search limit values\n",
    "queue_threshold =    #  <- fill with an integer for queue threshold\n",
    "#################################\n",
    "\n",
    "total_experiments = len(utilizations) * len(thresholds)\n",
    "exp = 1\n",
    "for utilization in utilizations:\n",
    "    sender_sl_results[utilization] = []\n",
    "    receiver_sl_results[utilization] = []\n",
    "    for limit in search_limits:\n",
    "        print(f'Experiment {exp} of {total_experiments}, search limit: {limit}, '\n",
    "              f'utilization ratio: {utilization}')\n",
    "        df = run_experiment(servers_number=servers_number, simulation_time=simulation_time, utilization=utilization,\n",
    "                                 policy=\"sender\", search_limit=limit, queue_threshold=queue_threshold)\n",
    "        sender_sl_results[utilization].append(df)\n",
    "\n",
    "        df = run_experiment(servers_number=servers_number, simulation_time=simulation_time, utilization=utilization,\n",
    "                                 policy=\"receiver\", search_limit=limit, queue_threshold=queue_threshold)\n",
    "        receiver_sl_results[utilization].append(df)\n",
    "        \n",
    "        exp += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ee78dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You don't need to change this part\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "colors_slice = colors[0:len(utilizations)]\n",
    "for i in range(len(utilizations)):\n",
    "    plot(search_limits, sender_sl_results[utilizations[i]], receiver_sl_results[utilizations[i]],\n",
    "         utilizations[i], ax0, ax1, colors_slice[i])\n",
    "    \n",
    "    ax0.set_xlabel('Search Limit')\n",
    "    ax0.set_ylabel('Total Messages')\n",
    "    ax0.legend()\n",
    "    \n",
    "    ax1.set_xlabel('Search Limit')\n",
    "    ax1.set_ylabel('Search Migrations')\n",
    "    ax1.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0a83e1",
   "metadata": {},
   "source": [
    "## Part 3 Questions (25 Points):\n",
    "\n",
    "#### Answer for both sender-initiated and receiver-initiated policies.\n",
    "\n",
    "#### What is the effect of increasing the search limit from 1 upwards on the total number of messages across the cluster? Why?\n",
    "*Your answer here.*\n",
    "\n",
    "#### What is the effect of increasing the search limit from 1 upwards on total migrations across the cluster? Why?\n",
    "*Your answer here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48ff4c7",
   "metadata": {},
   "source": [
    "### Part 4 Feedback (25 Points):\n",
    "\n",
    "Please fill the feedback form at https://docs.google.com/forms/d/1QALcmsoD73nB5WKGAXqJ4Omv1mCPPhonH2tfIsGF7NU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcea730c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
